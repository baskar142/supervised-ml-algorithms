{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7864afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#importing numpy libarary, It provides support for large, multi-dimensional arrays and matrices\n",
    "import numpy as np\n",
    "#importing numpy libarary, It provides support for data manipulation and analysis. \n",
    "import pandas as pd\n",
    "# importing matplotlib.pyplot plotting library in Python that provides a MATLAB-like interface for creating visualizations. \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10979481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3e4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)#1st column is dropped, CA is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c51d22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"User ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2f5cfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Purchased'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa82305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependet =data[[\"Purchased\"]]\n",
    "\n",
    "independet =data[[\"Age\", \"EstimatedSalary\", \"Gender_Male\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "125986b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split from sklearn.model_selection which is used for splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting Xtrain,X_test, y_train and y_test usiing train_test_split function. Train and test split ratio is 70% and 30% respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(independet, dependet, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ddfb65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AB92922\\AppData\\Local\\Temp\\ipykernel_18976\\2550333674.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(X_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10,criterion = 'entropy', random_state=0 )\n",
    "#regressor is fitting the X-train and y_train data\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928fc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18bd4b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a76143ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72,  7],\n",
       "       [ 6, 35]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c82e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70134415",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4290405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        79\n",
      "           1       0.83      0.85      0.84        41\n",
      "\n",
      "    accuracy                           0.89       120\n",
      "   macro avg       0.88      0.88      0.88       120\n",
      "weighted avg       0.89      0.89      0.89       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe746578",
   "metadata": {},
   "source": [
    "Precision: Precision measures the accuracy of the positive predictions made by the model.\n",
    "\n",
    "For class 0 (not purchased), the precision is 0.92. This means that out of all instances predicted as \"not purchased\" by the model, 92% were actually \"not purchased\".\n",
    "For class 1 (purchased), the precision is 0.83. This indicates that out of all instances predicted as \"purchased\" by the model, 83% were actually \"purchased\".\n",
    "\n",
    "\n",
    "Recall: Recall measures the model's ability to find all the positive instances.\n",
    "\n",
    "For class 0 (not purchased), the recall is 0.91. This means that the model correctly identified 91% of the actual \"not purchased\" instances.\n",
    "For class 1 (purchased), the recall is 0.85. This indicates that the model captured 85% of the actual \"purchased\" instances.\n",
    "\n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a single metric that combines both precision and recall.\n",
    "\n",
    "For class 0 (not purchased), the F1-score is 0.92. This reflects the balance between precision and recall for \"not purchased\".\n",
    "For class 1 (purchased), the F1-score is 0.84. This indicates a good balance between precision and recall for \"purchased\".\n",
    "\n",
    "\n",
    "Support: Support is the number of actual occurrences of each class in the test set.\n",
    "\n",
    "For class 0 (not purchased), there are 79 instances.\n",
    "For class 1 (purchased), there are 41 instances.\n",
    "\n",
    "\n",
    "Accuracy: The overall accuracy of the model across both classes is 0.89, meaning that the model predicted 89% of instances correctly.\n",
    "\n",
    "Macro Average:\n",
    "\n",
    "The macro-averaged precision, recall, and F1-score are all around 0.88. This indicates a balanced performance across classes, considering each class equally.\n",
    "Weighted Average:\n",
    "\n",
    "The weighted average precision, recall, and F1-score are all around 0.89. This reflects the overall performance of the model, considering class imbalances, as each class's contribution to the average is weighted by its support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63498041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AB92922\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([[41,44444,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67dd3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pickle file and  used for serializing and deserializing Python objects. \n",
    "import pickle\n",
    "#model saved in save fomat\n",
    "filenmae = 'RFclassification.sav'\n",
    "#pickle.dump() serializes the regressor object and writes it to the specified file (filename) in binary mode ('wb').\n",
    "pickle.dump(classifier, open(filenmae, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c7f6aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AB92922\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# the mode 'rb' used in file operations stands for \"read binary\" and saved in laoded model\n",
    "loaded_model = pickle.load(open('RFclassification.sav','rb'))\n",
    "#using predict keyeword, predicting 15 years of experience of emplyee and predicted value store in result variable\n",
    "result = loaded_model.predict([[41,44444,1]])\n",
    "#pring the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a38c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
